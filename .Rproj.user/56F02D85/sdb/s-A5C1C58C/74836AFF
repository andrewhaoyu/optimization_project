{
    "collab_server" : "",
    "contents" : "\nrm(list=ls())\noptions(error = recover);\n\nlibrary(rstan);\nlibrary(NlcOptim)\nlibrary(MASS)\nlibrary(mvtnorm)\nCI95_empircal <- function(post.bounds){\n  x <- post.bounds[,1]\n  y <- post.bounds[,2]\n  max_x <- quantile(x,probs = 0.05)\n  x.seq <- seq(min(x),max_x,0.001)\n  y.seq <- seq(min(y),max(y),0.001)\n  n <- nrow(post.bounds)\n  x.y <- expand.grid(x.seq,y.seq)\n  pdf <- rep(0,nrow((x.y)))\n  colnames(x.y) <- c(\"x\",\"y\")\n  for( i in 1:nrow(x.y)){\n    idx <- which(post.bounds[,1]>=x.y[i,1]&post.bounds[,2]<=x.y[i,2])\n    pdf[i] <- length(idx)/n\n  }\n  result <- data.frame(x.y,pdf=pdf)\n  \n  idx <- which(abs(result$pdf-0.95)<1e-03)\n  differ <- result$y[idx]-result$x[idx]\n  jdx <- which.min(differ)\n  x.y.95 <- cbind(result$x[idx],result$y[idx])\n  if(length(jdx)>1){\n    jdx <- jdx[1]\n  }\n  final <- x.y.95[jdx,]\n  return(final)\n}\nhin <- function(x){\n  h <- rep(NA,3)\n  h[1] <- x[2]-x[1]\n  h[2] <- x[1]\n  h[3] <- 1-x[2]\n  return(h)\n}\nhin.jac <- function(x){\n  j <- matrix(NA,3,2)\n  j[1,] <- c(-1,1)\n  j[2,] <- c(1,0)\n  j[3,] <- c(0,-1)\n  return(j)\n}\ncomputefunction <- function(a,b){\n  \n  mu1 <- mu[1]\n  sigma1 <- sqrt(Sigma[1,1])\n  result <- pmvnorm(lower=c(a,-Inf),upper = c(Inf,b),mean=mu,sigma=Sigma)\n  return((result[1]-0.95))\n}\n\nfn <- function(x){return(x[2]-x[1])}\ngr <- function(x){\n  g <- rep(NA,2)\n  g[1] <- -1\n  g[2] <- 1\n  return(g)\n}\nheq <- function(x){\n  h <- (computefunction(x[1],x[2]))\n  return(h)\n}\nheq.jac <- function(x){\n  j <- matrix(NA,1,length(x))\n  j[1,1] <- computefunction_grad_1(x[1],x[2])\n  j[1,2] <- computefunction_grad_2(x[1],x[2])\n  return(j)\n}\n\nCI_95 <- function(post.bounds){\n  \n  \n  p0 <- c(0.5,0.6)\n  ans <- auglag(par=p0,fn=fn,gr=gr,heq=heq,heq.jac = heq.jac,hin = hin,hin.jac = hin.jac)\n  return(ans$par)\n}\n\n\n\n\n\n\nstan.model <- \"\n data {\n    int<lower=0> N[6];\n }\n\ntransformed data {\n  vector[6] ones;\nfor (i in 1:6) {\nones[i] = 1;\n}\n}\n\n  parameters {\n    simplex[6] p;\n    real<lower=0, upper=1> q;\n  }\n\n  transformed parameters {\n    simplex[6] op;\n\n    op[1] = (1-q)*p[5];\n    op[2] = (1-q)*p[6];\n    op[3] = (1-q)*(p[1]+p[2]+p[3]+p[4]);\n    op[4] = q*(p[3] + p[5]);\n    op[5] = q*(p[4] + p[6]);\n    op[6] = q*(p[1] + p[2]);\n   }\n\n  model {\n    p  ~ dirichlet(ones);\n    q  ~ uniform(0,1);\n    N  ~ multinomial(op);\n  }\n\n  generated quantities {\n    real<lower=0, upper=1> tp[7];\n    real bounds[2];\n\n    tp[1] = p[6]/(p[5] + p[6]);\n    tp[2] = p[5] + p[6];\n    tp[3] = p[1] + p[2];\n    tp[4] = p[3] + p[4];\n    tp[5] = (p[4] + p[6])/(p[3]+p[4]+p[5]+p[6]);\n    tp[6] = p[4]/(p[3]+p[4]);\n    tp[7] = p[2] + p[4] + p[6];\n\n    bounds[1] = tp[5] * (tp[2] + tp[4]);\n    bounds[2] = tp[5] * (tp[2] + tp[4]) + tp[3];\n  }\n\n  \"\n\n\ngernating.function <- function(r0,r1){\n  result <- rep(0,length(r0))\n  idx <- which(r0==0&r1==0)\n  result[idx] <- (rbinom(length(idx),1,0.3)+1)\n  idx <- which(r0==0&r1==1)\n  result[idx] <- (rbinom(length(idx),1,0.5)+1)\n  idx <- which(r0==1&r1==1)\n  result[idx] <- (rbinom(length(idx),1,0.7)+1)\n  return(result)\n  \n}\n\n\n\nsimulationtimes <- 500\npost.95 <- matrix(0,simulationtimes,2)\npost.b <- matrix(0,simulationtimes,2)\ntrue.y.result <- rep(0,simulationtimes)\nset.seed(1234)\nfor(simulation in 1:simulationtimes){\n  n <-1500# total number of people\n  K <- 2 # number of levels for Likert outcome\n  result <- matrix(0,nrow=simulationtimes,ncol=(6+2*3*K*n))\n  final_result <- NULL\n  #simulation <- simulationtimes\n  \n  #print(paste0(\"we are in\",simulation,\"th run\"))\n  # n <-25# total number of people\n  # K <- 2 # number of levels for Likert outcome\n  # \n  # Start simulation\n  \n  #y <- sample(1:K,n,replace = T)\n  r1samp <- rbinom(n,1,0.8)\n  r2samp <- rbinom(n,1,0.5)\n  r0 <- pmin(r1samp,r2samp) # whether the individual will respond under low incentive\n  r1 <- pmax(r1samp,r2samp) # whether the individual will respond under high incentive\n  z <- rbinom(n,1,0.5) # the individual receive high or low incentive\n  r <- ifelse(z==1,r1,r0) # observed response indicator\n  \n  y <- gernating.function(r0,r1)\n  c <- cbind(sapply(1:K,function(sk) as.integer(r0==1 & y==sk)),sapply(1:K,function(sk) as.integer(r0==0 & r1==1 & y==sk)),sapply(1:K,function(sk) as.integer(r0==0 & r1==0 & y==sk)))\n  tmpid <- expand.grid(1:3,1:K)\n  colnames(c) <- apply(tmpid[order(tmpid[,1],tmpid[,2]),],1,paste0,collapse=\".\")\n  y <- y-1\n\n  completedata <- cbind(z,r,y)\n  \n  true.y <- mean(completedata[,3])\n  true.y.result[simulation] <- true.y\n  \n  \n  \n  idx <- which(r==0)\n  y[idx] <- NA\n  data <- cbind(z,r,y)\n  \n  data_count <- table(z,r,y,useNA = \"ifany\")\n  n010 <- data_count[[3]]\n  n110 <- data_count[[4]]\n  n011 <- data_count[[7]]\n  n111 <- data_count[[8]]\n  m00 <- data_count[[9]]\n  m10 <- data_count[[10]]\n  n.obs <- c(n010,n011,m00,n110,n111,m10)\n \n  p_int <- c(0.07,0.03,0.25,0.25,0.12,0.28)\n  q_int <- 0.5\n  # p6_int <- n.obs[2]/((1-q_int)*n)\n  # p5_int <- n.obs[1]/((1-q_int)*n)\n  # p3_int <- n.obs[4]/(q_int*n)-p5_int\n  # p4_int <- n.obs[5]/(q_int*n)-p6_int\n  # p2_int <- m10/(q_int*n/2)\n  # p1_int <- m10/(q_int*n/2)\n  # p_int_la <- c(p2_int,p3_int,p4_int,p5_int,p6_int)\n  # p_int_la1 <- p_int_la+runif(5,-0.01,0.01)\n  # p_int_la2 <- p_int_la+runif(5,-0.01,0.01)\n  # p_int_la3 <- p_int_la+runif(5,-0.01,0.01)\n  # p_int_la4 <- p_int_la+runif(5,-0.01,0.01)\n  # p_int_la5 <- p_int_la+runif(5,-0.01,0.01)\n  # p_int1 <- c(1-sum(p_int_la1),p_int_la1)\n  # p_int2 <- c(1-sum(p_int_la2),p_int_la2)\n  # p_int3 <- c(1-sum(p_int_la3),p_int_la3)\n  # p_int4 <- c(1-sum(p_int_la4),p_int_la4)\n  # p_int5 <- c(1-sum(p_int_la5),p_int_la5)\n  # \n  # \n  # p_int1 <- c(1-sum(p_int_la),p_int_la)\n  int <- list(list(p=p_int,q=q_int+runif(1,0,0.01)),\n              list(p=p_int,q=q_int+runif(1,0,0.01)),\n              list(p=p_int,q=q_int+runif(1,0,0.01)),\n              list(p=p_int,q=q_int+runif(1,0,0.01)),\n              list(p=p_int,q=q_int+runif(1,0,0.01))\n              )\n  \n  #n.obs <- c(100, 100, 100, 100, 100, 100);\n  #names(n.obs) <- c(\"n010\", \"n011\", \"m00\",\n  #                 \"n110\", \"n111\", \"m10\");\n  \n  rst <- stan(model_code = stan.model,\n              data = list(N=n.obs),\n              iter =20000, warmup = 6000, chains = 5,\n              thin = 5, verbose = TRUE,init = int);\n  print(rst);\n  \n  post.p <- extract(rst, \"p\")$p;\n  post.q <- extract(rst, \"q\")$q;\n  post.tp <- extract(rst, \"tp\")$tp;\n  post.bounds <- extract(rst, \"bounds\")$bounds;\n \n mu <- colMeans(post.bounds)\n  Sigma <- var(post.bounds)\n  mu1 <- mu[1]\n  mu2 <- mu[2]\n  sigma1 <- sqrt(2)\n  sigma2 <- sqrt(4)\n  p <- Sigma[1,2]/(sigma1*sigma2)\n  \n  \n  ##check if P(Y=1) is always in the bounds\n  mean(post.tp[,7] > post.bounds[,1] & post.tp[,7] < post.bounds[,2])\n  a <- CI95_empircal(post.bounds)\n  \n  post.95[simulation,1] <- a[1]\n  post.95[simulation,2] <- a[2]\n  post.b[simulation,] <- colMeans(post.bounds)\n  \n  \n}\n\n\nidx <- which(post.95[,1]<=0.53&post.95[,2]>=0.63)\njdx <- which(post.95[,1]<=true.y.result&post.95[,2]>=true.y.result)\npost.95 <- as.data.frame(post.95)\ncolnames(post.95) <- c(\"lower\",\"upper\")\nlibrary(ggplot2)\nplotdata <- data.frame(post.95,post.b)\ncolnames(plotdata) <- c(\"lower\",\"upper\",\"l\",\"u\")\nggplot(plotdata,aes(lower,upper))+geom_point()+geom_vline(xintercept=0.53)+geom_hline(yintercept = 0.63)+geom_point(aes(l,u),col=\"blue\")\n\nplotdata2 <- data.frame(post.bounds)\ncolnames(plotdata2) <- c(\"l\",\"u\")\nggplot(plotdata2,aes(l))+geom_density()\n",
    "created" : 1484341346346.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1157517688",
    "id" : "74836AFF",
    "lastKnownWriteTime" : 1484789425,
    "last_content_update" : 1484789425700,
    "path" : "~/Documents/study/advanced_stat_theory/optimization_project/counter_rcode.R",
    "project_path" : "counter_rcode.R",
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}